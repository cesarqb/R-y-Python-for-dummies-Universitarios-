{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Carga de modulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Carga de bases de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_diabetic_data = pd.read_csv('data/diabetic_data.csv')\n",
    "bd_AdmissionSource = pd.read_csv('data/admission_source_id.csv')\n",
    "bd_admission_type_id = pd.read_csv('data/admission_type_id.csv')\n",
    "bd_discharge_disposition_id = pd.read_csv('data/discharge_disposition_id.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comprobar correcta lectura de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_AdmissionSource.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Juntamos las bases de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_diabetes1 = pd.merge(bd_diabetic_data,bd_AdmissionSource, on = \"admission_source_id\", how = \"left\")\n",
    "bd_diabetes2 = pd.merge(bd_diabetes1,bd_admission_type_id, on = \"admission_type_id\", how = \"left\" )\n",
    "bd_full = pd.merge(bd_diabetes2,bd_discharge_disposition_id, on = \"discharge_disposition_id\", how  = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Renombramos las variables por buenas prácticas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsNameDiabetes = [\"encounter_id\", \"patient_nbr\", \"race\", \"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\",\n",
    "                       \"admission_source_id\", \"time_in_hospital\", \"payer_code\", \"medical_specialty\", \"num_lab_procedures\", \"num_procedures\",\n",
    "                       \"num_medications\", \"number_outpatient\", \"number_emergency\", \"number_inpatient\", \"diag_1\", \"diag_2\", \"diag_3\",\n",
    "                       \"number_diagnoses\", \"max_glu_serum\", \"a1c_result\", \"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\",\n",
    "                       \"glimepiride\", \"acetohexamide\", \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \"acarbose\",\n",
    "                       \"miglitol\", \"troglitazone\", \"tolazamide\", \"examide\", \"citoglipton\", \"insulin\", \"glyburide_metformin\", \"glipizide_metformin\",\n",
    "                       \"glimepiride_pioglitazone\", \"metformin_rosiglitazone\", \"metformin_pioglitazone\", \"change\", \"diabetes_med\", \"readmitted\",\n",
    "                       \"description_x\", \"description_y\", \"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Analizamos la variable target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de filas: \" + str(bd_full.shape[0]))\n",
    "print(\"Número de columnas: \" + str(bd_full.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full[\"readmitted\"].describe()\n",
    "bd_full.groupby(\"readmitted\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTarget = \"target\"\n",
    "bd_full[columnTarget] = bd_full[\"readmitted\"].map({\"NO\":0,\"<30\":1,\">30\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Diferenciamos los tipos de variables por buenas practicas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsNumeric = [\"time_in_hospital\", \"num_lab_procedures\", \"num_procedures\", \"num_medications\", \"number_outpatient\", \"number_emergency\",\n",
    "                   \"number_inpatient\", \"number_diagnoses\"]\n",
    "columnsString = [\"race\", \"gender\", \"age\", \"weight\", \"payer_code\", \"medical_specialty\", \"diag_1\", \"diag_2\", \"diag_3\",\n",
    "                   \"max_glu_serum\", \"a1c_result\", \"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\", \"glimepiride\", \"acetohexamide\",\n",
    "                   \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \"acarbose\", \"miglitol\", \"troglitazone\", \"tolazamide\",\n",
    "                   \"examide\", \"citoglipton\", \"insulin\", \"glyburide_metformin\", \"glipizide_metformin\", \"glimepiride_pioglitazone\", \"metformin_rosiglitazone\",\n",
    "                   \"metformin_pioglitazone\", \"change\", \"diabetes_med\", \"description_x\", \"description_y\", \"description\"]\n",
    "columnTarget = \"target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Estudiamos las variables numericas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full[columnsNumeric].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*analizamos las varianzas mas cercanas a cero*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full[columnsNumeric].var().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hacemos un analisis de frecuencia a la variable: number_emergency porqeu tiene la varianza mas pequeña*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Revisamos las frecuencias de las variables numéricas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frecuencia (x):\n",
    "    frec = bd_full.groupby(x).size()/bd_full[x].shape[0]\n",
    "    print(frec)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A las variables \"number_outpatient\", \"number_emergency\" y \"number_inpatient\" hacemos un analisis de frecuencia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frecuencia(\"number_outpatient\"))\n",
    "print(frecuencia(\"number_emergency\"))\n",
    "print(frecuencia(\"number_inpatient\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Viendo presencia de valores perdidos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columnsNumeric:\n",
    "    print(x)\n",
    "    print(bd_full.loc[(pd.isna(bd_full[x]))].shape[0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Viendo presencia de atípicos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(bd_full[\"time_in_hospital\"] , 0, 'gD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de Identificar Outliers:\n",
    "def calcularOutliars(x):\n",
    "  Q01 = x.quantile(0.25)\n",
    "  Q03 = x.quantile(0.75)\n",
    "  IQR = Q03 - Q01\n",
    "  a = (x < (Q01 - 1.5 * IQR)) | (x > (Q03 + 1.5 * IQR))\n",
    "  numOutliars = a[a == True].shape[0]\n",
    "  pornumOutliars = numOutliars/x.shape[0]\n",
    "  return pornumOutliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcularOutliars(bd_full[\"time_in_hospital\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columnsNumeric:\n",
    "    print(x)\n",
    "    print(calcularOutliars(bd_full[x]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputamos los valores outliers en nuevas variables\n",
    "#==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable number_diagnoses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bd_full[columnsNumeric].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retiramos variables numéricas\n",
    "columnsNumeric.remove('number_diagnoses')\n",
    "columnsNumeric.remove('num_lab_procedures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aderimos las nuevas variables numéricas\n",
    "columnsNumeric = columnsNumeric + [\"number_diagnoses_imp\"] + [\"num_lab_procedures_imp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observamos que se acumulan en 0 pero no en un 90% (no en la gran mayoria), lo tendremos en cuenta en la exploración de datos para descartarlas de ser necesario con más evidencia (mean encoding)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para las variables categoricas vemos sus distribuciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corregimos las variables que no están definidas de forma correcta como NaN (nan)\n",
    "for x in columnsString:\n",
    "    print(x)\n",
    "    print(bd_full.groupby(x).size())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazamos los valores extraños\n",
    "bd_full[\"race\"] = bd_full[\"race\"].replace(\"?\",np.nan)\n",
    "bd_full[\"gender\"] = bd_full[\"gender\"].replace(\"Unknown/Invalid\",np.nan)\n",
    "bd_full[\"weight\"] = bd_full[\"weight\"].replace(\"?\",np.nan)\n",
    "bd_full[\"payer_code\"] = bd_full[\"payer_code\"].replace(\"?\",np.nan)\n",
    "bd_full[\"medical_specialty\"] = bd_full[\"medical_specialty\"].replace(\"?\",np.nan)\n",
    "bd_full[\"medical_specialty\"] = bd_full[\"medical_specialty\"].replace(\"?\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viendo presencia de valores perdidos\n",
    "for x in columnsString:\n",
    "    print(x)\n",
    "    print(bd_full.loc[(pd.isna(bd_full[x]))].shape[0]/bd_full[x].shape[0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retiramos las variables con muchos NAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como el porcentaje de nan es menor al 1% eliminamos los casos perdidos para un mejor ajuste\n",
    "bd_full =  bd_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas categoricas\n",
    "for x in columnsString:\n",
    "  plt.title(x)\n",
    "  bd_full.fillna(\"--NULL\").groupby(x)[x].count().plot(kind = \"bar\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retiramos las variables diag_1 diag_2 diag_3\n",
    "columnsNumeric.append(\"diag_1\")\n",
    "columnsNumeric.append(\"diag_2\")\n",
    "columnsNumeric.append(\"diag_3\")\n",
    "\n",
    "columnsString.remove(\"diag_1\")\n",
    "columnsString.remove(\"diag_2\")\n",
    "columnsString.remove(\"diag_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se observa que las variables diag_1, diag_2 y diag_3 son en su mayoria numéricas, revisamos el porcentaje de numéricas, no numericas y nulos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeType(x):\n",
    "  try:\n",
    "    a = float(x)\n",
    "    if(np.isnan(a)):\n",
    "      return -1\n",
    "    else:\n",
    "      return 1\n",
    "  except:\n",
    "    return 0\n",
    "  \n",
    "def diagToNumber(x):\n",
    "  try:\n",
    "    a = float(x)\n",
    "    if(np.isnan(a)):\n",
    "      return float(\"nan\")\n",
    "    else:\n",
    "      return a\n",
    "  except:\n",
    "    return float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"diag_1\", \"diag_2\", \"diag_3\"]:\n",
    "  numNumeric = bd_full[bd_full[x].apply(changeType) == 1].shape[0]\n",
    "  numString = bd_full[bd_full[x].apply(changeType) == 0].shape[0]\n",
    "  numNull = bd_full[bd_full[x].apply(changeType) == -1].shape[0]\n",
    "  print(x)\n",
    "  print(\"Numeros: \" + str(np.round(numNumeric / bd_full.shape[0] * 100, 2)) + \"%\")\n",
    "  print(\"String: \" + str(np.round(numString / bd_full.shape[0] * 100, 2)) + \"%\")\n",
    "  print(\"Nulos: \" + str(np.round(numNull / bd_full.shape[0] * 100, 2)) + \"%\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Todos los numéricos son mayores a 90%, tomamos estos para transformar a numéricas estas variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"diag_1\", \"diag_2\", \"diag_3\"]:\n",
    "  bd_full[x] = bd_full[x].apply(diagToNumber)\n",
    "  bd_full[x] = bd_full[x].apply(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Transformamos las variables categoricas para que puedan ser leidas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como el porcentaje de nan es menor al 1% eliminamos los casos perdidos para un mejor ajuste\n",
    "bd_full =  bd_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columnsString:\n",
    "    le.fit(bd_full[x])\n",
    "    le.transform(bd_full[x]) \n",
    "    bd_full[x + '_D'] = le.transform(bd_full[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columnsString_D = ['race_D', 'gender_D', 'age_D', 'max_glu_serum_D', 'a1c_result_D', 'metformin_D', 'repaglinide_D', 'nateglinide_D',\n",
    " 'chlorpropamide_D', 'glimepiride_D', 'acetohexamide_D', 'glipizide_D', 'glyburide_D', 'tolbutamide_D', 'pioglitazone_D', 'rosiglitazone_D',\n",
    " 'acarbose_D', 'miglitol_D', 'troglitazone_D', 'tolazamide_D', 'examide_D', 'citoglipton_D', 'insulin_D', 'glyburide_metformin_D',\n",
    " 'glipizide_metformin_D', 'glimepiride_pioglitazone_D', 'metformin_rosiglitazone_D', 'metformin_pioglitazone_D', 'change_D',\n",
    " 'diabetes_med_D', 'description_x_D', 'description_y_D', 'description_D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. REDUCCIÓN DE DIMENSIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(bd_full[columnsNumeric])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pca.components_)):\n",
    "    print('% Var. explicada ('+str(i+1)+' componentes): ', np.cumsum(pca.explained_variance_ratio_)[i]*100)\n",
    "    \n",
    "plt.bar(range(1,len(pca.components_)+1),pca.explained_variance_ratio_, alpha=.2,color='0')\n",
    "plt.plot(range(1,len(pca.components_)+1),np.cumsum(pca.explained_variance_ratio_),alpha=4)\n",
    "plt.title(\"Varianza explicada y pareto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full[columnsNumeric].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. ANALISIS CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables a trabajar\n",
    "var_trabajar = columnsNumeric + columnsString_D\n",
    "var_trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(bd_full[var_trabajar])\n",
    "\n",
    "Nc = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]\n",
    "kmeans\n",
    "score = [kmeans[i].fit(x_train).score(x_train) for i in range(len(kmeans))]\n",
    "score\n",
    "plt.plot(Nc,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los indicadores para escoger el nro de cluster óptimos\n",
    "ctdDf = int(0.1*bd_full.shape[0])\n",
    "cluster = [kmeans[i].predict(x_train) for i in range(len(kmeans))]\n",
    "\n",
    "for i in range(1,19):    \n",
    "    print(str(i+1)+' clústeres:')\n",
    "    print('Inercia: '+str(kmeans[i].inertia_))\n",
    "    print('Silueta: '+str(metrics.silhouette_score(x_train, cluster[i], metric='euclidean',sample_size=ctdDf)))\n",
    "    print('Distancias: '+str(pairwise_distances_argmin_min(kmeans[i].cluster_centers_, x_train)[0]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escogemos el nro de cluster adeucdo\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.predict(x_train)\n",
    "bd_full[\"cluster03\"] = kmeans.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full.groupby('cluster03').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Generamos nuestra base modeler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsEvaluar = columnsNumeric + [\"cluster03\"] + columnsString_D + [\"target\"]\n",
    "bd_modeler = bd_full[columnsEvaluar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Particionado de datos: train y Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = bd_modeler[columnsEvaluar]\n",
    "y = bd_modeler[[\"target\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdX_train = pd.DataFrame(X_train, columns = columnsEvaluar)\n",
    "pdy_train = pd.DataFrame(y_train, columns = [\"target\"])\n",
    "pdX_test = pd.DataFrame(X_test, columns = columnsEvaluar)\n",
    "pdy_test = pd.DataFrame(y_test, columns = [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión logistica\n",
    "#==============#============\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clasificador = LogisticRegression()\n",
    "clasificador.fit(pdX_train[columnsEvaluar], y_train)   \n",
    "\n",
    "prediction_train = clasificador.score(pdX_train[columnsEvaluar], y_train)\n",
    "prediction_test = clasificador.score(pdX_test[columnsEvaluar], y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arboles de Decisiones:    \n",
    "#==============#============\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clasificador2 = DecisionTreeClassifier(max_depth = 40)\n",
    "clasificador2.fit(pdX_train[columnsEvaluar], y_train)\n",
    "\n",
    "prediction2_train = clasificador2.score(pdX_train[columnsEvaluar], y_train)\n",
    "prediction2_test = clasificador2.score(pdX_test[columnsEvaluar], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo GBoosting:\n",
    "#=====#============\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clasificador3 = GradientBoostingClassifier(n_estimators=200, max_depth = 4, learning_rate = .4)\n",
    "clasificador3.fit(pdX_train[columnsEvaluar], pdy_train)\n",
    "\n",
    "prediction3_train = clasificador3.score(pdX_train[columnsEvaluar], pdy_train)\n",
    "prediction3_test = clasificador3.score(pdX_test[columnsEvaluar], pdy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
